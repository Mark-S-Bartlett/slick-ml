{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/amirhessam/Documents/GitHub/slick-ml\n"
     ]
    }
   ],
   "source": [
    "# # Change path to project root\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "# widen the screen\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "# change the path and loading class\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%autoreload\n",
    "from slickml.optimization import XGBoostClassifierBayesianOpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoostClassifierBayesianOpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>58.0</td>\n",
       "      <td>249.30</td>\n",
       "      <td>456.47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.7</td>\n",
       "      <td>6.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>260.92</td>\n",
       "      <td>443.43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.2</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>59.0</td>\n",
       "      <td>255.63</td>\n",
       "      <td>478.96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>49.0</td>\n",
       "      <td>195.28</td>\n",
       "      <td>381.94</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.6</td>\n",
       "      <td>17.0</td>\n",
       "      <td>259.55</td>\n",
       "      <td>395.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    F1   F2   F3    F4      F5      F6  CLASS\n",
       "0  5.7  4.7  3.7  58.0  249.30  456.47      0\n",
       "1  7.7  6.6  4.1  20.0  260.92  443.43      1\n",
       "2  6.2  4.3  4.6  59.0  255.63  478.96      1\n",
       "3  5.7  4.4  3.8  49.0  195.28  381.94      0\n",
       "4  9.1  4.7  4.6  17.0  259.55  395.67      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading data\n",
    "df = pd.read_csv(\"data/dummy_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X, y\n",
    "y = df.CLASS.values\n",
    "X = df.drop([\"CLASS\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    shuffle=True,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=1367)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define bayesian optimizer \n",
    "xbo = XGBoostClassifierBayesianOpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |   gamma   | learni... | max_depth | min_ch... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8245  \u001b[0m | \u001b[0m 0.8975  \u001b[0m | \u001b[0m 0.04571 \u001b[0m | \u001b[0m 0.6628  \u001b[0m | \u001b[0m 4.238   \u001b[0m | \u001b[0m 1.436   \u001b[0m | \u001b[0m 0.3064  \u001b[0m | \u001b[0m 0.7136  \u001b[0m | \u001b[0m 0.1931  \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.8374  \u001b[0m | \u001b[95m 0.7904  \u001b[0m | \u001b[95m 0.6447  \u001b[0m | \u001b[95m 0.9152  \u001b[0m | \u001b[95m 3.334   \u001b[0m | \u001b[95m 3.238   \u001b[0m | \u001b[95m 0.7772  \u001b[0m | \u001b[95m 0.269   \u001b[0m | \u001b[95m 0.9726  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.8199  \u001b[0m | \u001b[0m 0.8498  \u001b[0m | \u001b[0m 0.6044  \u001b[0m | \u001b[0m 0.6874  \u001b[0m | \u001b[0m 6.651   \u001b[0m | \u001b[0m 15.7    \u001b[0m | \u001b[0m 0.061   \u001b[0m | \u001b[0m 0.5114  \u001b[0m | \u001b[0m 0.6848  \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.8551  \u001b[0m | \u001b[95m 0.7297  \u001b[0m | \u001b[95m 0.8513  \u001b[0m | \u001b[95m 0.4627  \u001b[0m | \u001b[95m 4.757   \u001b[0m | \u001b[95m 4.965   \u001b[0m | \u001b[95m 0.9328  \u001b[0m | \u001b[95m 0.363   \u001b[0m | \u001b[95m 0.9365  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.8173  \u001b[0m | \u001b[0m 0.5425  \u001b[0m | \u001b[0m 0.5451  \u001b[0m | \u001b[0m 0.8782  \u001b[0m | \u001b[0m 6.633   \u001b[0m | \u001b[0m 5.028   \u001b[0m | \u001b[0m 0.1845  \u001b[0m | \u001b[0m 0.333   \u001b[0m | \u001b[0m 0.9125  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.8099  \u001b[0m | \u001b[0m 0.4336  \u001b[0m | \u001b[0m 0.282   \u001b[0m | \u001b[0m 0.3017  \u001b[0m | \u001b[0m 4.288   \u001b[0m | \u001b[0m 16.0    \u001b[0m | \u001b[0m 0.06196 \u001b[0m | \u001b[0m 0.8237  \u001b[0m | \u001b[0m 0.8923  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.8386  \u001b[0m | \u001b[0m 0.5277  \u001b[0m | \u001b[0m 0.7101  \u001b[0m | \u001b[0m 0.3167  \u001b[0m | \u001b[0m 2.901   \u001b[0m | \u001b[0m 9.436   \u001b[0m | \u001b[0m 0.6913  \u001b[0m | \u001b[0m 0.1258  \u001b[0m | \u001b[0m 0.6468  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.8075  \u001b[0m | \u001b[0m 0.1291  \u001b[0m | \u001b[0m 0.225   \u001b[0m | \u001b[0m 0.8967  \u001b[0m | \u001b[0m 6.216   \u001b[0m | \u001b[0m 3.886   \u001b[0m | \u001b[0m 0.5093  \u001b[0m | \u001b[0m 0.2564  \u001b[0m | \u001b[0m 0.3911  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.8546  \u001b[0m | \u001b[0m 0.7847  \u001b[0m | \u001b[0m 0.8845  \u001b[0m | \u001b[0m 0.4636  \u001b[0m | \u001b[0m 4.454   \u001b[0m | \u001b[0m 4.869   \u001b[0m | \u001b[0m 0.969   \u001b[0m | \u001b[0m 0.3627  \u001b[0m | \u001b[0m 0.98    \u001b[0m |\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m 0.8644  \u001b[0m | \u001b[95m 0.8214  \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 0.2315  \u001b[0m | \u001b[95m 4.571   \u001b[0m | \u001b[95m 5.633   \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 0.3947  \u001b[0m | \u001b[95m 1.0     \u001b[0m |\n",
      "=========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# train the optimizer on train set\n",
    "xbo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>gamma</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>subsample</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.897530</td>\n",
       "      <td>0.045712</td>\n",
       "      <td>0.662807</td>\n",
       "      <td>4.238468</td>\n",
       "      <td>1.435660</td>\n",
       "      <td>0.306424</td>\n",
       "      <td>0.713585</td>\n",
       "      <td>0.193055</td>\n",
       "      <td>0.824512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.790404</td>\n",
       "      <td>0.644709</td>\n",
       "      <td>0.915190</td>\n",
       "      <td>3.334492</td>\n",
       "      <td>3.238280</td>\n",
       "      <td>0.777161</td>\n",
       "      <td>0.269010</td>\n",
       "      <td>0.972576</td>\n",
       "      <td>0.837449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.849819</td>\n",
       "      <td>0.604370</td>\n",
       "      <td>0.687435</td>\n",
       "      <td>6.651023</td>\n",
       "      <td>15.698338</td>\n",
       "      <td>0.061001</td>\n",
       "      <td>0.511379</td>\n",
       "      <td>0.684811</td>\n",
       "      <td>0.819881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.729727</td>\n",
       "      <td>0.851274</td>\n",
       "      <td>0.462704</td>\n",
       "      <td>4.756996</td>\n",
       "      <td>4.964748</td>\n",
       "      <td>0.932765</td>\n",
       "      <td>0.362983</td>\n",
       "      <td>0.936539</td>\n",
       "      <td>0.855133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.542456</td>\n",
       "      <td>0.545092</td>\n",
       "      <td>0.878165</td>\n",
       "      <td>6.632704</td>\n",
       "      <td>5.028311</td>\n",
       "      <td>0.184497</td>\n",
       "      <td>0.333049</td>\n",
       "      <td>0.912511</td>\n",
       "      <td>0.817250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.433647</td>\n",
       "      <td>0.281979</td>\n",
       "      <td>0.301710</td>\n",
       "      <td>4.287809</td>\n",
       "      <td>15.997975</td>\n",
       "      <td>0.061965</td>\n",
       "      <td>0.823726</td>\n",
       "      <td>0.892268</td>\n",
       "      <td>0.809917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.527662</td>\n",
       "      <td>0.710147</td>\n",
       "      <td>0.316749</td>\n",
       "      <td>2.901123</td>\n",
       "      <td>9.435776</td>\n",
       "      <td>0.691293</td>\n",
       "      <td>0.125812</td>\n",
       "      <td>0.646834</td>\n",
       "      <td>0.838585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.129065</td>\n",
       "      <td>0.224998</td>\n",
       "      <td>0.896721</td>\n",
       "      <td>6.215583</td>\n",
       "      <td>3.885759</td>\n",
       "      <td>0.509329</td>\n",
       "      <td>0.256423</td>\n",
       "      <td>0.391094</td>\n",
       "      <td>0.807489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.784692</td>\n",
       "      <td>0.884516</td>\n",
       "      <td>0.463588</td>\n",
       "      <td>4.454321</td>\n",
       "      <td>4.869008</td>\n",
       "      <td>0.969036</td>\n",
       "      <td>0.362743</td>\n",
       "      <td>0.979997</td>\n",
       "      <td>0.854646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.821392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.231482</td>\n",
       "      <td>4.570813</td>\n",
       "      <td>5.632603</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.394688</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.864417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   colsample_bytree     gamma  learning_rate  max_depth  min_child_weight  \\\n",
       "0          0.897530  0.045712       0.662807   4.238468          1.435660   \n",
       "1          0.790404  0.644709       0.915190   3.334492          3.238280   \n",
       "2          0.849819  0.604370       0.687435   6.651023         15.698338   \n",
       "3          0.729727  0.851274       0.462704   4.756996          4.964748   \n",
       "4          0.542456  0.545092       0.878165   6.632704          5.028311   \n",
       "5          0.433647  0.281979       0.301710   4.287809         15.997975   \n",
       "6          0.527662  0.710147       0.316749   2.901123          9.435776   \n",
       "7          0.129065  0.224998       0.896721   6.215583          3.885759   \n",
       "8          0.784692  0.884516       0.463588   4.454321          4.869008   \n",
       "9          0.821392  1.000000       0.231482   4.570813          5.632603   \n",
       "\n",
       "   reg_alpha  reg_lambda  subsample       auc  \n",
       "0   0.306424    0.713585   0.193055  0.824512  \n",
       "1   0.777161    0.269010   0.972576  0.837449  \n",
       "2   0.061001    0.511379   0.684811  0.819881  \n",
       "3   0.932765    0.362983   0.936539  0.855133  \n",
       "4   0.184497    0.333049   0.912511  0.817250  \n",
       "5   0.061965    0.823726   0.892268  0.809917  \n",
       "6   0.691293    0.125812   0.646834  0.838585  \n",
       "7   0.509329    0.256423   0.391094  0.807489  \n",
       "8   0.969036    0.362743   0.979997  0.854646  \n",
       "9   1.000000    0.394688   1.000000  0.864417  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimization results (or xbo.optimization_results_)\n",
    "xbo.get_optimization_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>gamma</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>subsample</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.821392</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.231482</td>\n",
       "      <td>4.570813</td>\n",
       "      <td>5.632603</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.394688</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.864417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   colsample_bytree  gamma  learning_rate  max_depth  min_child_weight  \\\n",
       "0          0.821392    1.0       0.231482   4.570813          5.632603   \n",
       "\n",
       "   reg_alpha  reg_lambda  subsample       auc  \n",
       "0        1.0    0.394688        1.0  0.864417  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best performance (or xbo.best_performance_)\n",
    "xbo.get_best_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8213916662259918,\n",
       " 'gamma': 1.0,\n",
       " 'learning_rate': 0.23148232373451072,\n",
       " 'max_depth': 4,\n",
       " 'min_child_weight': 5.632602921054691,\n",
       " 'reg_alpha': 1.0,\n",
       " 'reg_lambda': 0.39468801734425263,\n",
       " 'subsample': 1.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tuned params (or xbo.best_params_)\n",
    "xbo.get_best_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bayes_opt.bayesian_optimization.BayesianOptimization at 0x7f1c443f2810>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimizer object (or xbo.optimizer_)\n",
    "xbo.get_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': (2, 7),\n",
       " 'learning_rate': (0, 1),\n",
       " 'min_child_weight': (1, 20),\n",
       " 'colsample_bytree': (0.1, 1.0),\n",
       " 'subsample': (0.1, 1),\n",
       " 'gamma': (0, 1),\n",
       " 'reg_alpha': (0, 1),\n",
       " 'reg_lambda': (0, 1)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimization params boundaries \n",
    "xbo.get_pbounds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': (2, 7),\n",
       " 'learning_rate': (0, 1),\n",
       " 'min_child_weight': (1, 20),\n",
       " 'colsample_bytree': (0.1, 1.0),\n",
       " 'subsample': (0.1, 1),\n",
       " 'gamma': (0, 1),\n",
       " 'reg_alpha': (0, 1),\n",
       " 'reg_lambda': (0, 1)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbo.pbounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bayes_opt import BayesianOptimization\n",
    "# import xgboost as xgb\n",
    "# import numpy as np\n",
    "# import pandas as pd \n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.preprocessing import scale\n",
    "# import warnings\n",
    "# warnings.simplefilter(\"ignore\")\n",
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "# import seaborn as sns\n",
    "# sns.set_style(\"ticks\")\n",
    "# %matplotlib inline\n",
    "\n",
    "# def _my_bayesian_optimization(X, Y, n_iter = 5,\n",
    "#                                        init_points = 5,\n",
    "#                                        acq = \"ei\",\n",
    "#                                        num_boost_round = 1000,\n",
    "#                                        nfold = 10,\n",
    "#                                        stratified = True,\n",
    "#                                        metrics = (\"auc\"),\n",
    "#                                        early_stopping_rounds = 20,\n",
    "#                                        seed = 1367,\n",
    "#                                        shuffle = True,\n",
    "#                                        show_stdv = False,\n",
    "#                                        pbounds = None,\n",
    "#                                        importance_type = \"total_gain\",\n",
    "#                                        callbacks = False,\n",
    "#                                        verbose_eval = False):\n",
    "#     \"\"\"\n",
    "#     a function to run bayesian optimization for xgboost\n",
    "#     input parameters:\n",
    "#                     X: features (pandas dataframe or numpy array)\n",
    "#                     Y: targets (1D array or list)\n",
    "#                     n_iter: total number of bayesian iterations (default = 5)\n",
    "#                     init_points: total initial points of optimization (default = 5)\n",
    "#                     acq\n",
    "#                     num_boost_rounds: max number of boosting rounds, (default = 1000)\n",
    "#                     stratified: stratificaiton of the targets (default = True)\n",
    "#                     metrics: classification/regression metrics (default = (\"auc))\n",
    "#                     early_stopping_rounds: the criteria for stopping if the test metric is not improved (default = 20)\n",
    "#                     seed: random seed (default = 1367)\n",
    "#                     shuffle: shuffling the data (default = True)\n",
    "#                     show_stdv = showing standard deviation of cv results (default = False)\n",
    "#                     pbounds = set of parameters for bayesian optimization of xgboost cv\n",
    "#                             (default_params = {\n",
    "#                                                \"eval_metric\" : \"auc\",\n",
    "#                                                \"tree_method\": \"hist\",\n",
    "#                                                \"objective\" : \"binary:logistic\",\n",
    "#                                                \"learning_rate\" : 0.05,\n",
    "#                                                \"max_depth\": 2,\n",
    "#                                                \"min_child_weight\": 1,\n",
    "#                                                \"gamma\" : 0.0,\n",
    "#                                                \"reg_alpha\" : 0.0,\n",
    "#                                                \"reg_lambda\" : 1.0,\n",
    "#                                                \"subsample\" : 0.9,\n",
    "#                                                \"max_delta_step\": 1,\n",
    "#                                                \"silent\" : 1,\n",
    "#                                                \"nthread\" : 4,\n",
    "#                                                \"scale_pos_weight\" : 1\n",
    "#                                                }\n",
    "#                             )\n",
    "#                     importance_type = importance type of xgboost as string (default = \"total_gain\")\n",
    "#                                       the other options will be \"weight\", \"gain\", \"cover\", and \"total_cover\"\n",
    "#                     callbacks = printing callbacks for xgboost cv\n",
    "#                                 (defaults = False, if True: [xgb.callback.print_evaluation(show_stdv = show_stdv),\n",
    "#                                                              xgb.callback.early_stop(early_stopping_rounds)])\n",
    "#                     verbose_eval : a flag to show the result during train on train/test sets (default = False)\n",
    "#     outputs:\n",
    "#             df_res: the parameters related to the best performance\n",
    "#             xgb_params: a dictionary of the best parameters of xgboost                \n",
    "    \n",
    "    \n",
    "#     \"\"\"\n",
    "\n",
    "    \n",
    "#     # callback flag\n",
    "#     if(callbacks == True):\n",
    "#         callbacks = [xgb.callback.print_evaluation(show_stdv = show_stdv),\n",
    "#                      xgb.callback.early_stop(early_stopping_rounds)]\n",
    "#     else:\n",
    "#         callbacks = None    \n",
    "    \n",
    "#     # pbounds\n",
    "#     default_pbounds = {\"max_depth\" : (2, 5),\n",
    "#                        \"learning_rate\" : (0, 1), \n",
    "#                        \"min_child_weight\" : (1, 20),\n",
    "#                        \"subsample\" : (0.1, 1),\n",
    "#                        \"gamma\": (0, 1),\n",
    "#                        \"colsample_bytree\": (0.1, 1.0)\n",
    "#                       }\n",
    "    \n",
    "#     # updating the default parameters of the pbounds\n",
    "#     if pbounds is not None:\n",
    "#         for key, val in pbounds.items():\n",
    "#             default_pbounds[key] = val\n",
    "    \n",
    "    \n",
    "#     def __xgb_eval(learning_rate,\n",
    "#                    max_depth,\n",
    "#                    gamma,\n",
    "#                    colsample_bytree,\n",
    "#                    min_child_weight,\n",
    "#                    subsample):\n",
    "\n",
    "#         params = {\"eval_metric\" : \"auc\",\n",
    "#                   \"tree_method\": \"hist\",\n",
    "#                   \"objective\" : \"binary:logistic\",\n",
    "#                   \"max_delta_step\": 1,\n",
    "#                   \"silent\" : 1,\n",
    "#                   \"nthread\" : 4,\n",
    "#                   \"scale_pos_weight\" : 1,\n",
    "#                   \"reg_alpha\" : 0.0,\n",
    "#                   \"reg_lambda\" : 1.0,\n",
    "#                   \"learning_rate\" : learning_rate,\n",
    "#                   \"max_depth\": int(max_depth),\n",
    "#                   \"min_child_weight\": min_child_weight,\n",
    "#                   \"gamma\" : gamma,\n",
    "#                   \"subsample\" : subsample,\n",
    "#                   \"colsample_bytree\" : colsample_bytree \n",
    "#                  }\n",
    "#         dtrain = xgb.DMatrix(data = X, label = Y)\n",
    "#         cv_result = xgb.cv(params = params,\n",
    "#                            dtrain = dtrain,\n",
    "#                            num_boost_round = num_boost_round,\n",
    "#                            nfold = nfold,\n",
    "#                            stratified = stratified,\n",
    "#                            metrics = metrics,\n",
    "#                            early_stopping_rounds = early_stopping_rounds,\n",
    "#                            seed = seed,\n",
    "#                            verbose_eval = verbose_eval,\n",
    "#                            shuffle = shuffle,\n",
    "#                            callbacks = callbacks)\n",
    "\n",
    "#         return cv_result.iloc[-1][2]\n",
    "    \n",
    "\n",
    "#     xgb_bo = bo(__xgb_eval, default_pbounds, random_state = seed, verbose = 3)\n",
    "#     xgb_bo.maximize(init_points = init_points, n_iter = n_iter, acq = acq)\n",
    "    \n",
    "    \n",
    "#     targets = []\n",
    "#     for i, rs in enumerate(xgb_bo.res):\n",
    "#         targets.append(rs[\"target\"])\n",
    "#     best_params = xgb_bo.res[targets.index(max(targets))][\"params\"]\n",
    "#     best_params[\"max_depth\"] = int(best_params[\"max_depth\"])\n",
    "    \n",
    "#     xgb_params = {\"eval_metric\" : \"auc\",\n",
    "#                   \"tree_method\": \"hist\",\n",
    "#                   \"objective\" : \"binary:logistic\",\n",
    "#                   \"max_delta_step\": 1,\n",
    "#                   \"silent\" : 1,\n",
    "#                   \"nthread\" : 4,\n",
    "#                   \"scale_pos_weight\" : 1,\n",
    "#                   \"reg_alpha\" : 0.0,\n",
    "#                   \"reg_lambda\" : 1.0,\n",
    "#                   \"learning_rate\" : 0.05,\n",
    "#                   \"max_depth\": 2,\n",
    "#                   \"min_child_weight\": 5,\n",
    "#                   \"gamma\" : 0.0,\n",
    "#                   \"subsample\" : 1.0,\n",
    "#                   \"colsample_bytree\" : 0.9 \n",
    "#                  }\n",
    "#     for key, val in best_params.items():\n",
    "#         xgb_params[key] = val\n",
    "    \n",
    "#     dtrain = xgb.DMatrix(data = X, label = Y)\n",
    "#     bst = xgb.train(params = xgb_params,\n",
    "#                     dtrain = dtrain,\n",
    "#                     num_boost_round = num_boost_round)\n",
    "    \n",
    "#     # build results dataframe\n",
    "#     frames = []\n",
    "#     for idx, res in enumerate(xgb_bo.res):\n",
    "#         d = res['params']\n",
    "#         d[metrics] = res[\"target\"]\n",
    "#         frames.append(pd.DataFrame(data = d, index = [idx]))\n",
    "    \n",
    "#     res_df = pd.concat(frames)\n",
    "   \n",
    "#     print(F\"-*-*-*-*-*-* Optimization Results -*-*-*-*-*-*\")\n",
    "#     display(res_df)\n",
    "    \n",
    "#     # Plotting\n",
    "#     import matplotlib as mpl\n",
    "\n",
    "#     mpl.rcParams['axes.linewidth'] = 3 \n",
    "#     mpl.rcParams['lines.linewidth'] = 3\n",
    "#     cols = [col for col in res_df.columns.tolist() if col != \"auc\"]\n",
    "#     ip = 1\n",
    "#     plt.figure(figsize = (22, 10))\n",
    "#     colors = [\"navy\", \"lavender\", \"lightblue\", \"cyan\", \"cadetblue\", \"slateblue\"]\n",
    "#     for col in cols:\n",
    "#         res_df.sort_values(by = col, inplace=True)\n",
    "#         plt.subplot(2,3,ip)\n",
    "#         plt.plot(res_df.loc[:, col], res_df.loc[:, metrics], color = colors[ip-1])\n",
    "#         plt.xlabel(F\"{col}\", fontsize = 20)\n",
    "#         plt.ylabel(F\"{metrics}\", fontsize = 20)\n",
    "#         plt.tick_params(axis='both', which='major', labelsize = 12)\n",
    "#         ip += 1\n",
    "#     plt.show()\n",
    "    \n",
    "#     print(F\"-*-*-*-*-*-* Best Performance -*-*-*-*-*-*\")\n",
    "#     display(res_df.loc[res_df[metrics] == res_df[metrics].max(), :])\n",
    "    \n",
    "#     from xgboost import plot_importance\n",
    "#     from pylab import rcParams\n",
    "#     rcParams['figure.figsize'] = (10,10)\n",
    "#     plot_importance(bst, importance_type = importance_type, color = \"skyblue\", xlabel = importance_type)\n",
    "#     plt.show()   \n",
    "    \n",
    "#     return res_df, xgb_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
